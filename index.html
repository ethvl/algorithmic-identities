<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>A-I: Algorithmic Identities</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="/favicon.png" />

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="assets/styles.css">

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.9.1/gsap.min.js"></script>

    <style>
        /* Essential styling for the animation container */
        #animation-container {
            width: 100%;
            height: 100vh;
            /* Fill the right panel */
            position: relative;
            overflow: hidden;
            background-color: #ffffff;
        }

        #loading-info {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #888;
            font-family: monospace;
            pointer-events: none;
            z-index: 10;
            letter-spacing: 4px;
            text-transform: uppercase;
            font-size: 12px;
        }

        /* Ensure right panel doesn't scroll excessively */
        .right-panel.index-page {
            overflow: hidden;
            padding: 0 !important;
            /* Remove padding to let canvas touch edges */
        }
    </style>
</head>

<body>

    <div class="page-shell">

        <aside class="left-rail">

            <div class="site-title-block">
                <div class="site-kicker">
                    <a href="/index.html">A-I: Algorithmic Identities</a>
                </div>
                <p class="site-description">
                    A design-research project exploring how our digital identities are co-constructed by algorithms,
                    shaping who we become online.
                </p>
            </div>

            <nav class="nav-groups">
                <div class="nav-group overview-group">
                    <button class="nav-toggle" aria-expanded="false">
                        <span>SEM 1 / OVERVIEW</span>
                        <span class="nav-toggle-symbol">+</span>
                    </button>
                    <ul class="overview-weeks">
                        <li><a href="/semester-1/week-1.html"><strong>W1</strong> : Prologue</a></li>
                        <li><a href="/semester-1/week-2.html"><strong>W2</strong> : Atelier Presentation</a></li>
                        <li><a href="/semester-1/week-3.html"><strong>W3</strong> : Mindmap & E-1</a></li>
                        <li><a href="/semester-1/week-4.html"><strong>W4</strong> : RPO Plan & P-1</a></li>
                        <li><a href="/semester-1/week-5.html"><strong>W5</strong> : RPO Consult & RE-1</a></li>
                        <li><a href="/semester-1/week-6.html"><strong>W6</strong> : RPO Peer Reviews</a></li>
                        <li><a href="/semester-1/week-7.html"><strong>W7</strong> : Formative Assessment</a></li>
                        <li><a href="/semester-1/week-8.html"><strong>W8</strong> : E-2</a></li>
                        <li><a href="/semester-1/week-9.html"><strong>W9</strong> : ASM & AxiDraw</a></li>
                        <li><a href="/semester-1/week-10.html"><strong>W10</strong> : Task-Based Making</a></li>
                        <li><a href="/semester-1/week-11.html"><strong>W11</strong> : E-3 - 6</a></li>
                        <li><a href="/semester-1/week-12.html"><strong>W12</strong> : P-2</a></li>
                        <li><a href="/semester-1/week-13.html"><strong>W13</strong> : Cohort Presentation</a></li>
                        <li><a href="/semester-1/week-14.html"><strong>W14</strong> : P-3</a></li>
                        <li><a href="/semester-1/week-15.html"><strong>W15</strong> : E- 7 & P-4</a></li>
                    </ul>
                </div>

                <div class="nav-group overview-group">
                    <button class="nav-toggle" aria-expanded="false">
                        <span>SEM 2 / OVERVIEW</span>
                        <span class="nav-toggle-symbol">+</span>
                    </button>
                    <ul class="overview-weeks">
                        <li><a href="/semester-2/week-1.html"><strong>W1</strong> : SEM-1 Review</a></li>
                        <li><a href="/semester-2/week-2.html"><strong>W2</strong> : DISS Consult & P-5</a></li>
                        <li><a href="/semester-2/week-3.html"><strong>W3</strong> : GDI Interview & P-6</a></li>
                    </ul>
                </div>

                <div class="nav-group"><a class="nav-link" href="/catalogue.html">Catalogue of Making</a></div>
                <div class="nav-group"><a class="nav-link" href="/repository.html">Repository</a></div>
                <div class="nav-group"><a class="nav-link" href="/about.html">About</a></div>
            </nav>

            <div class="left-rail-footer">
                © ETHEL LIM<br>
                CiD / 2025
            </div>

        </aside>

        <main class="right-panel index-page">
            <div id="animation-container">
                <div id="loading-info">INITIALIZING SYSTEM...</div>
            </div>
        </main>

    </div>


    <script>
        document.addEventListener("DOMContentLoaded", () => {
            document.querySelectorAll(".overview-group").forEach(group => {
                const toggleBtn = group.querySelector(".nav-toggle");
                const symbol = group.querySelector(".nav-toggle-symbol");

                if (!toggleBtn || !symbol) return;

                group.classList.remove("is-open");
                toggleBtn.setAttribute("aria-expanded", "false");
                symbol.textContent = "+";

                toggleBtn.addEventListener("click", () => {
                    const isOpen = group.classList.toggle("is-open");
                    toggleBtn.setAttribute("aria-expanded", isOpen ? "true" : "false");
                    symbol.textContent = isOpen ? "−" : "+";
                });
            });
        });
    </script>

    <script>
        // --- CONFIGURATION ---
        const MASONRY_GRID_SIZE = 45;
        const VOXEL_SIZE = 12;
        const VOXEL_GAP = 1;

        // YOUR IMAGE
        const TARGET_IMAGE_URL = 'assets/images/Kate Bush by Fresno.jpeg';

        // DATA SOURCE: SIMULATED USER SUBMISSIONS
        // These words will form the "Outline" of the identity
        const SUBMITTED_WORDS = [
            "IDENTITY", "DATA", "PROFILE", "SEARCH", "CLICK", "LIKE", "SHARE",
            "VIEW", "LOG", "USER", "CACHE", "COOKIE", "ALGORITHM", "TRACE",
            "SCAN", "UPLOAD", "DIGITAL", "SELF", "INPUT", "OUTPUT"
        ];

        const IMAGE_URLS = [
            'https://picsum.photos/id/106/200/200',
            'https://picsum.photos/id/700/200/200',
            'https://picsum.photos/id/189/200/200',
            'https://picsum.photos/id/348/200/200',
            'https://picsum.photos/id/453/200/200',
            'https://picsum.photos/id/542/200/200',
            'https://picsum.photos/id/564/200/200',
            'https://picsum.photos/id/487/200/200',
        ];

        // --- HELPER: GENERATE TEXT TEXTURE ---
        function createTextTexture(word) {
            const cvs = document.createElement('canvas');
            cvs.width = 128; cvs.height = 64; // Rectangular for words
            const ctx = cvs.getContext('2d');

            // Transparent BG
            // Text Style
            ctx.font = 'bold 35px Arial';
            ctx.fillStyle = '#111'; // Dark Grey text
            ctx.textAlign = 'center';
            ctx.textBaseline = 'middle';

            // Add a "Tag" background for readability
            ctx.fillStyle = '#ffffff';
            ctx.fillRect(10, 10, 108, 44);

            ctx.fillStyle = '#000000';
            ctx.fillText(word, 64, 32);

            const tex = new THREE.CanvasTexture(cvs);
            return tex;
        }

        // --- 1. IMAGE SAMPLER WITH EDGE DETECTION ---
        function sampleImage(imageObj) {
            const w = 100;
            const aspect = imageObj.width / imageObj.height;
            const h = Math.floor(w / aspect);
            const canvas = document.createElement('canvas');
            canvas.width = w; canvas.height = h;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(imageObj, 0, 0, w, h);
            const imgData = ctx.getImageData(0, 0, w, h).data;
            const targets = [];
            const offX = -(w * (VOXEL_SIZE + VOXEL_GAP)) / 2;
            const offY = (h * (VOXEL_SIZE + VOXEL_GAP)) / 2;

            // Helper to get brightness of a pixel at x,y
            function getB(x, y) {
                if (x < 0 || x >= w || y < 0 || y >= h) return 0; // Out of bounds is dark
                const idx = (y * w + x) * 4;
                return (imgData[idx] + imgData[idx + 1] + imgData[idx + 2]) / 3;
            }

            for (let y = 0; y < h; y++) {
                for (let x = 0; x < w; x++) {
                    const currentB = getB(x, y);

                    if (currentB > 50) {
                        // EDGE DETECTION LOGIC
                        // Check neighbors (Up, Down, Left, Right). 
                        // If any neighbor is dark (<50), this pixel is on the edge.
                        let isEdge = false;
                        if (getB(x + 1, y) < 50 || getB(x - 1, y) < 50 ||
                            getB(x, y + 1) < 50 || getB(x, y - 1) < 50) {
                            isEdge = true;
                        }

                        const i = (y * w + x) * 4;
                        targets.push({
                            x: offX + (x * (VOXEL_SIZE + VOXEL_GAP)),
                            y: offY - (y * (VOXEL_SIZE + VOXEL_GAP)),
                            z: 0,
                            color: new THREE.Color(`rgb(${imgData[i]},${imgData[i + 1]},${imgData[i + 2]})`),
                            isEdge: isEdge // Mark this target as an outline candidate
                        });
                    }
                }
            }
            return targets;
        }

        // --- 2. TEXT SAMPLER (Unchanged) ---
        function sampleText() {
            const w = 250; const h = 100;
            const canvas = document.createElement('canvas');
            canvas.width = w; canvas.height = h;
            const ctx = canvas.getContext('2d');
            ctx.fillStyle = 'black'; ctx.fillRect(0, 0, w, h);
            ctx.font = 'bold 24px Arial'; ctx.fillStyle = 'white';
            ctx.textAlign = 'center'; ctx.textBaseline = 'middle';
            ctx.fillText("ALGORITHMIC", w / 2, h / 2 - 15);
            ctx.fillText("IDENTITIES", w / 2, h / 2 + 15);

            const imgData = ctx.getImageData(0, 0, w, h).data;
            const targets = [];
            const offX = -(w * (VOXEL_SIZE + VOXEL_GAP)) / 2;
            const offY = (h * (VOXEL_SIZE + VOXEL_GAP)) / 2;

            for (let y = 0; y < h; y++) {
                for (let x = 0; x < w; x++) {
                    if (imgData[(y * w + x) * 4] > 128) {
                        targets.push({
                            x: offX + (x * (VOXEL_SIZE + VOXEL_GAP)),
                            y: offY - (y * (VOXEL_SIZE + VOXEL_GAP)),
                            z: 0
                        });
                    }
                }
            }
            return targets;
        }

        function init(faceTargets, textTargets) {
            const container = document.getElementById('animation-container');
            const width = container.clientWidth;
            const height = container.clientHeight;

            const scene = new THREE.Scene();
            scene.background = new THREE.Color(0xffffff);
            scene.fog = new THREE.Fog(0xffffff, 800, 3000);

            const camera = new THREE.PerspectiveCamera(50, width / height, 1, 5000);
            camera.position.set(0, 0, 1600);
            camera.lookAt(0, 0, 0);

            const renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(width, height);
            renderer.shadowMap.enabled = true;
            renderer.shadowMap.type = THREE.PCFSoftShadowMap;
            container.appendChild(renderer.domElement);

            const lightKey = new THREE.DirectionalLight(0xffffff, 1.0);
            lightKey.position.set(200, 500, 600);
            lightKey.castShadow = true;
            lightKey.shadow.mapSize.width = 2048;
            lightKey.shadow.mapSize.height = 2048;
            scene.add(lightKey);

            const lightFill = new THREE.DirectionalLight(0x4444ff, 0.3);
            lightFill.position.set(-500, 100, 200);
            scene.add(lightFill);
            scene.add(new THREE.AmbientLight(0x606060));

            // -- LOAD ASSETS --
            const textureLoader = new THREE.TextureLoader();
            const loadedTextures = IMAGE_URLS.map(url => {
                textureLoader.setCrossOrigin('anonymous');
                return textureLoader.load(url);
            });

            // Generate Text Textures for the Words
            const wordMaterials = SUBMITTED_WORDS.map(word => {
                return new THREE.MeshBasicMaterial({
                    map: createTextTexture(word),
                    transparent: true,
                    color: 0xffffff
                });
            });

            const boxGeo = new THREE.BoxGeometry(1, 1, 1);
            const imageMaterialCache = loadedTextures.map(tex => new THREE.MeshStandardMaterial({
                map: tex, roughness: 0.5, metalness: 0.0, color: 0xffffff
            }));

            // -- GRID CALC --
            const cols = Math.ceil(width / MASONRY_GRID_SIZE) + 2;
            const rows = Math.ceil(height / MASONRY_GRID_SIZE) + 2;
            const totalScreenSlots = cols * rows;
            const TOTAL_PARTICLES = Math.max(faceTargets.length, totalScreenSlots, textTargets.length);

            const gridMap = new Array(cols * rows).fill(false);
            function checkAndOccupy(c, r, w, h) {
                if (c + w > cols || r + h > rows) return false;
                for (let i = 0; i < w; i++) for (let j = 0; j < h; j++) if (gridMap[(r + j) * cols + (c + i)]) return false;
                for (let i = 0; i < w; i++) for (let j = 0; j < h; j++) gridMap[(r + j) * cols + (c + i)] = true;
                return true;
            }

            const particles = [];
            const group = new THREE.Group();
            scene.add(group);

            const shuffledFaceIndices = Array.from({ length: faceTargets.length }, (_, i) => i).sort(() => Math.random() - 0.5);
            const shuffledTextIndices = Array.from({ length: textTargets.length }, (_, i) => i).sort(() => Math.random() - 0.5);

            for (let i = 0; i < TOTAL_PARTICLES; i++) {

                // --- DETERMINE ROLE ---
                const isFace = i < faceTargets.length;
                const faceIndex = isFace ? shuffledFaceIndices[i] : -1;
                const isText = isFace && (i < textTargets.length);
                const textIndex = isText ? shuffledTextIndices[i] : -1;

                const faceTargetData = isFace ? faceTargets[faceIndex] : null;

                // --- MATERIAL SELECTION ---
                // If this particle targets a FACE EDGE, make it a WORD.
                // Otherwise, make it an IMAGE.
                let mat, geometry;
                let isWordParticle = false;

                if (isFace && faceTargetData.isEdge) {
                    // Assign a random word from our submitted list
                    mat = wordMaterials[Math.floor(Math.random() * wordMaterials.length)].clone();
                    geometry = boxGeo; // We use box so it has depth
                    isWordParticle = true;
                } else {
                    // Standard Image Block
                    mat = imageMaterialCache[Math.floor(Math.random() * imageMaterialCache.length)].clone();
                    geometry = boxGeo;
                }

                // --- MASONRY START POS ---
                const w = Math.random() > 0.85 ? 2 : 1;
                const h = Math.random() > 0.85 ? 2 : 1;
                let c = Math.floor(Math.random() * cols);
                let r = Math.floor(Math.random() * rows);

                if (!checkAndOccupy(c, r, w, h)) {
                    let found = false;
                    for (let rr = 0; rr < rows && !found; rr++) {
                        for (let cc = 0; cc < cols && !found; cc++) {
                            if (checkAndOccupy(cc, rr, w, h)) { c = cc; r = rr; found = true; }
                        }
                    }
                }
                const startX = (c * MASONRY_GRID_SIZE) + (w * MASONRY_GRID_SIZE) / 2 - (cols * MASONRY_GRID_SIZE) / 2;
                const startY = -((r * MASONRY_GRID_SIZE) + (h * MASONRY_GRID_SIZE) / 2) + (rows * MASONRY_GRID_SIZE) / 2;

                const mesh = new THREE.Mesh(geometry, mat);
                mesh.position.set(startX, startY, 0);
                mesh.scale.set(w * MASONRY_GRID_SIZE - 2, h * MASONRY_GRID_SIZE - 2, 5);
                mesh.castShadow = true;
                mesh.receiveShadow = true;

                mesh.userData = {
                    isFace: isFace,
                    isText: isText,
                    isWordParticle: isWordParticle,
                    faceTarget: faceTargetData,
                    textTarget: isText ? textTargets[textIndex] : null,
                };
                group.add(mesh);
                particles.push(mesh);
            }

            const tl = gsap.timeline({ repeat: -1, repeatDelay: 2, yoyo: true });

            // WAIT
            tl.to({}, { duration: 1.5 });

            // --- PHASE 1: GRID -> FACE ---
            const faceParticles = particles.filter(p => p.userData.isFace);
            const noiseParticles = particles.filter(p => !p.userData.isFace);

            // 1. Transform Scale
            // Words stay slightly larger to be readable
            tl.to(faceParticles.map(p => p.scale), {
                duration: 1.5,
                x: i => faceParticles[i].userData.isWordParticle ? VOXEL_SIZE * 2.5 : VOXEL_SIZE, // Words are wider
                y: VOXEL_SIZE,
                z: 5,
                ease: "power2.inOut"
            }, "toFace");

            // 2. Colorize
            // For Image particles: Tint to Face Color.
            // For Word particles: Keep them White/Black (Readable) or Tint slightly.
            tl.to(faceParticles.map(p => p.material.color), {
                duration: 1.5,
                r: i => faceParticles[i].userData.isWordParticle ? 1 : faceParticles[i].userData.faceTarget.color.r,
                g: i => faceParticles[i].userData.isWordParticle ? 1 : faceParticles[i].userData.faceTarget.color.g,
                b: i => faceParticles[i].userData.isWordParticle ? 1 : faceParticles[i].userData.faceTarget.color.b,
                ease: "power2.inOut"
            }, "toFace");

            tl.to(noiseParticles.map(p => p.position), {
                duration: 1.5, y: "-=1000", z: "-=500", ease: "power2.in"
            }, "toFace");
            tl.to(noiseParticles.map(p => p.material), {
                duration: 1.0, opacity: 0, ease: "power2.in"
            }, "toFace");

            tl.to(faceParticles.map(p => p.position), {
                duration: 1.8,
                x: i => faceParticles[i].userData.faceTarget.x,
                y: i => faceParticles[i].userData.faceTarget.y,
                z: i => faceParticles[i].userData.faceTarget.z,
                ease: "power3.inOut",
                stagger: { amount: 0.5, from: "random" }
            }, "formFace");

            tl.to(faceParticles.map(p => p.rotation), {
                duration: 2.0, x: 0, y: 0, z: 0, ease: "power2.out"
            }, "formFace");

            // WAIT
            tl.to({}, { duration: 3.0 });

            // --- PHASE 2: FACE -> TEXT ---
            const textParticles = particles.filter(p => p.userData.isText);
            const leftoverFaceParticles = particles.filter(p => p.userData.isFace && !p.userData.isText);

            tl.to(textParticles.map(p => p.position), {
                duration: 2.0,
                x: i => textParticles[i].userData.textTarget.x,
                y: i => textParticles[i].userData.textTarget.y,
                z: 0,
                ease: "power4.inOut",
                stagger: { amount: 0.5, from: "center" }
            }, "toText");

            // REVEAL CONTENT ON TEXT
            // Set everything to White so textures show clearly
            tl.to(textParticles.map(p => p.material.color), {
                duration: 2.0,
                r: 1, g: 1, b: 1,
                ease: "power2.inOut"
            }, "toText");

            // Scale Words down slightly if they end up in the text
            tl.to(textParticles.map(p => p.scale), {
                duration: 2.0,
                x: VOXEL_SIZE, // Reset to square
                y: VOXEL_SIZE,
                ease: "power2.inOut"
            }, "toText");

            tl.to(leftoverFaceParticles.map(p => p.material), {
                duration: 1.0, opacity: 0, ease: "power2.out"
            }, "toText");
            tl.to(leftoverFaceParticles.map(p => p.scale), {
                duration: 1.0, x: 0, y: 0, ease: "power2.out"
            }, "toText");

            // WAIT
            tl.to({}, { duration: 3.0 });

            function animate() {
                requestAnimationFrame(animate);
                renderer.render(scene, camera);
            }
            animate();
            document.getElementById('loading-info').style.display = 'none';

            window.addEventListener('resize', () => {
                const newWidth = container.clientWidth;
                const newHeight = container.clientHeight;
                camera.aspect = newWidth / newHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(newWidth, newHeight);
            });
        }

        const userImg = new Image();
        userImg.crossOrigin = "Anonymous";
        userImg.src = TARGET_IMAGE_URL;

        userImg.onload = function () {
            const faceData = sampleImage(userImg);
            const textData = sampleText();
            init(faceData, textData);
        };

        userImg.onerror = function () { document.getElementById('loading-info').innerText = "ERROR: Load Failed."; };

    </script>

</body>

</html>