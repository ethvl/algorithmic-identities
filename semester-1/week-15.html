<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>A-I: S1-W15</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <base href="/algorithmic-identities/">

    <link rel="icon" href="favicon.png" />
    <link rel="stylesheet" href="/algorithmic-identities/assets/styles.css">
</head>

<body>

    <div class="page-shell">

        <!-- FIXED LEFT NAV BAR -->
        <aside class="left-rail">
            <div class="site-title-block">
                <div class="site-kicker"><a href="index.html">A-I: Algorithmic Identities</a></div>
                <p class="site-description">
                    A design-research project exploring how our digital identities are co-constructed by algorithms,
                    shaping who we become online.
                </p>
            </div>

            <!-- NAVIGATION -->
            <nav class="nav-groups">
                <div class="nav-group overview-group">
                    <button class="nav-toggle" aria-expanded="false">
                        <span>SEM 1 / OVERVIEW</span>
                        <span class="nav-toggle-symbol">+</span>
                    </button>

                    <ul class="overview-weeks">
                        <li><a href="semester-1/week-1.html"><strong>W1</strong> : Prologue</a></li>
                        <li><a href="semester-1/week-2.html"><strong>W2</strong> : Atelier Presentation</a></li>
                        <li><a href="semester-1/week-3.html"><strong>W3</strong> : Mindmap & E-1</a></li>
                        <li><a href="semester-1/week-4.html"><strong>W4</strong> : RPO Plan & P-1</a></li>
                        <li><a href="semester-1/week-5.html"><strong>W5</strong> : RPO Consult & RE-1</a></li>
                        <li><a href="semester-1/week-6.html"><strong>W6</strong> : RPO Peer Reviews</a></li>
                        <li><a href="semester-1/week-7.html"><strong>W7</strong> : Formative Assessment</a></li>
                        <li><a href="semester-1/week-8.html"><strong>W8</strong> : E-2</a></li>
                        <li><a href="semester-1/week-9.html"><strong>W9</strong> : ASM & AxiDraw</a></li>
                        <li><a href="semester-1/week-10.html"><strong>W10</strong> : Task-Based Making</a></li>
                        <li><a href="semester-1/week-11.html"><strong>W11</strong> : E-3 - 6</a></li>
                        <li><a href="semester-1/week-12.html"><strong>W12</strong> : P-2</a></li>
                        <li><a href="semester-1/week-13.html"><strong>W13</strong> : Cohort Presentation</a></li>
                        <li><a href="semester-1/week-14.html"><strong>W14</strong> : P-3</a></li>
                        <li><a href="semester-1/week-15.html" class="active"><strong>W15</strong> : E-7 & P-4</a></li>
                    </ul>
                </div>

                <div class="nav-group overview-group">
                    <button class="nav-toggle" aria-expanded="false">
                        <span>SEM 2 / OVERVIEW</span>
                        <span class="nav-toggle-symbol">+</span>
                    </button>

                    <ul class="overview-weeks">
                        <li><a href="semester-2/week-1.html"><strong>W1</strong> : SEM-1 Review</a></li>
                        <li><a href="semester-2/week-2.html"><strong>W2</strong> : E-8</a></li>
                        <li><a href="semester-2/week-3.html"><strong>W3</strong> : P-6 & GDI Interview</a></li>
                        <li><a href="semester-2/week-4.html"><strong>W4</strong> : Exploring Arduino</a></li>
                        <li><a href="semester-2/week-5.html"><strong>W5</strong> : Exhibit 3D Model</a></li>
                    </ul>
                </div>

                <div class="nav-group"><a class="nav-link" href="catalogue.html">Catalogue of Making</a></div>
                <div class="nav-group"><a class="nav-link" href="repository.html">Repository</a></div>
                <div class="nav-group"><a class="nav-link" href="about.html">About</a></div>
            </nav>

            <div class="left-rail-footer">
                © ETHEL LIM<br>
                CiD / 2025
            </div>
        </aside>


        <!-- RIGHT PANEL — TWO COLUMN CONTENT -->

        <main class="right-panel">

            <section class="catalogue-sidebar">
                <h1><strong>Week 15</strong> / Experiment 7 & Prototype 4</h1>
            </section>

            <!-- ROW 4 — FULL WIDTH IMAGE -->
            <section class="exp-row full">
                <video src="assets/videos/e7-hover.mp4" autoplay muted loop playsinline
                    style="border-radius: 0px; border: 0;"></video>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Experiment 7: ID://ASCII</strong></h3>
                </div>

                <div class="exp-block">
                    <!-- <div class="exp-block" style="overflow:hidden;">
                        <video src="assets/videos/p2-visuals.mp4" autoplay muted loop playsinline alt=""
                            style="width:100%; height:100%; object-fit:cover; flex:1; transform-origin:center; margin-bottom:20px; border: 0; transform: scale(1.0); margin-bottom: 30px;"></video>
                    </div> -->
                    <p style="margin-top: 0px;"><strong><em>How much of a person can a machine reconstruct from the
                                smallest digital traces?</em></strong>
                    </p>
                    <p><strong>ID://ASCII</strong> examines how algorithmic identities are constructed from the smallest
                        actions we make online. In this experiment, I set up a simple constraint: users must choose
                        three ASCII characters, and those characters become the only vocabulary the system is allowed to
                        use. This limitation mirrors the quiet but powerful ways algorithms construct our digital
                        identities from small, seemingly insignificant choices of tiny inputs such as likes, follows,
                        pauses, scrolls, become the foundations of how systems “see” us.</p>
                    <p>Once the characters are selected, the system performs a series of transformations that reveal how
                        a living human presence is continuously reduced by computational logic:</p>
                    <p><strong>⑴ Live Silhouette Capture: </strong>The camera extracts the user’s outline, turning a
                        moving, expressive body into a static contour—the first step of algorithmic simplification.</p>
                    <p><strong>⑵ Silhouette → ASCII Mosaic:</strong> The shape is rebuilt entirely using the three
                        chosen characters, showing how personal actions become the limited raw material for algorithmic
                        reconstruction.</p>
                    <p><strong>⑶ ASCII Density Mapping:</strong> Character density shifts according to brightness,
                        echoing how systems weight certain behaviours more heavily, amplifying some traces while
                        diminishing others.</p>
                    <p><strong>⑷ Side-by-Side Display:</strong> The live camera feed sits beside the ASCII version,
                        making visible the gap between self-perception and algorithmic interpretation, a reminder that
                        what the system “knows” is only ever a compressed approximation.</p>
                    <p>I made these transformations intentionally minimal and mechanical. I wanted them to reveal the
                        reduction process rather than beautifying it, emphasising how algorithms flatten our
                        individuality into legible formats. The work exposes how our algorithmic identities emerge not
                        from who we are, but from the small traces we leave behind, and how easily those traces can
                        become the whole identity.</p>
                    <p><em>Read more about the algorithmic process breakdown in <strong>Experiment 7's Catalogue of
                                Making.</strong></em></p>
                    <!-- BUTTON ALIGNED TO LEFT, AT BOTTOM -->
                    <a href="https://editor.p5js.org/ethel.limpy/full/qEcqMQnWU" class="launch-btn"
                        style="font-size: 14px; padding:6px 14px; margin-top:20px; display:inline-block;"
                        target="_blank">
                        Try Experiment 7
                    </a>
                    <!-- BUTTON: Link to Experiment 2's Catalogue of Making -->
                    <a href="experiments/experiment-7.html" class="launch-btn-revert"
                        style="font-size: 14px; padding:6px 14px; margin-top:20px; display:inline-block;">
                        Catalogue of Making (Experiment 7)
                    </a>
                </div>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split" style="margin-bottom: 60px;">
                <div class="exp-block">
                    <h3><strong>Output</strong></h3>
                </div>

                <div class="exp-block">
                </div>
            </section>

            <!-- 4 COLUMNS -->
            <section class="exp-row cols-4">
                <div class="exp-block"><img src="assets/images/ascii_experiment_canvas (4).png"></div>
                <div class="exp-block"><img src="assets/images/ascii_experiment_canvas (1).png"></div>
                <div class="exp-block"><img src="assets/images/ascii_experiment_canvas (3).png"></div>
                <div class="exp-block"><img src="assets/images/ascii_experiment_canvas (5).png"></div>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Process & Challenges</strong></h3>
                </div>

                <div class="exp-block">
                    <p>I had to navigate several significant challenges building this experiment. It required solving
                        both conceptual and technical challenges, because the experience depends on synchronising three
                        things at once: user choice, live camera input, and ASCII-based reconstruction.</p>
                    <p>Extracting the user's silhouette was the most challenging part of the experiment because it is
                        the most complex part of the system. I had to work with raw pixel arrrays from a mirrored feed,
                        make sure edges detect clearly under different lighting, and filter out noise while preserving
                        the human outline. The edge detection was poor and I had to seek <strong>ChatGPT's</strong> help
                        with using Sobel Edge Detection to convert the frame to greyscale, re-index pixels to account
                        for the mirrored input, and apply Sobel gradient kernels. To ensure the <strong>ASCII</strong>
                        appears clean, I had to thicken the outline by dilating the edges. This part required multiple
                        iterations because too much thresholding erased the face entirely, while too little made the
                        <strong>ASCII</strong> messy and noisy.
                    </p>
                    <p>Once the system isolates the edges, it must translate them into <strong>ASCII</strong>
                        characters. Every "pixel block" has to correspond cleanly to a region of the camera feed, and I
                        had to map out character placement so the silhouette appears recognisable. Initial verions
                        redrew characters randomly each frame which caused flicker, but fixing the grid solved this.</p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/w15-p4.jpeg" alt="" style="object-fit: cover;">
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Prototype 4: Reconstructed Self</strong></h3>
                </div>

                <div class="exp-block">
                    <p style="margin-top: 0px;"><strong><em>If you met your algorithmic double, would you recognise
                                it?</em></strong>
                    </p>
                    <p>At first glance, <strong>Reconstructed Self</strong> might look like a fun activity where you can
                        look at yourself, draw yourself, and watch the system "draw" you back. But beneath that playful
                        framing lies a critical examination of how identity is constructed across different systems.</p>
                    <p>I designed the experiment with three parallel views: the live camera feed, the user’s hand-drawn
                        self-portrait, and the ASCII portrait generated by the system. Each one follows different rules
                        of representation, embodied, expressive, and computational, mirroring how our gestures, clicks,
                        and pauses online are constantly interpreted through multiple layers.</p>
                    <p>Once the user finishes drawing, the system transforms the camera feed into an ASCII identity,
                        revealing how computational logic reduces what it sees:</p>
                    <p><strong>⑴ Live Embodied Self:</strong>The left panel shows the user’s mirrored presence—a fluid,
                        continuous reflection of the body.</p>
                    <p><strong>⑵ Drawn Expressive Self:</strong> The middle panel captures how the user imagines
                        themselves, full of subjectivity and intentional expression.</p>
                    <p><strong>⑶ ASCII Algorithmic Self:</strong> The right panel reconstructs the user using only the
                        three chosen ASCII characters, flattening the face into a symbolic, compressed data portrait.
                    </p>
                    <p>These three views outline a clear progression from lived experience to computational abstraction.
                        The experiment reveals how identity is never singular; it is constantly split, interpreted, and
                        reassembled. What begins as a simple drawing activity ultimately exposes the hidden violence of
                        reduction, how algorithms compress us into simplified silhouettes so we can be profiled, sorted,
                        and fed back into digital systems that shape how we are seen.</p>
                    <p><em>Read more about the algorithmic process breakdown in <strong>Experiment 7's Catalogue of
                                Making.</strong></em></p>
                    <!-- BUTTON ALIGNED TO LEFT, AT BOTTOM -->
                    <a href="https://editor.p5js.org/ethel.limpy/full/YW4-TKpsw" class="launch-btn"
                        style="font-size: 14px; padding:6px 14px; margin-top:20px; display:inline-block;"
                        target="_blank">
                        Try Prototype 4
                    </a>
                    <!-- BUTTON: Link to Experiment 2's Catalogue of Making -->
                    <a href="prototypes/prototype-4.html" class="launch-btn-revert"
                        style="font-size: 14px; padding:6px 14px; margin-top:20px; display:inline-block;">
                        Catalogue of Making (Prototype 4)
                    </a>
                </div>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split" style="margin-bottom: 60px;">
                <div class="exp-block">
                    <h3><strong>Output</strong></h3>
                </div>

                <div class="exp-block">
                </div>
            </section>
            <section class="exp-row cols-4">

                <figure class="exp-block" style="margin:0; padding:0; display:flex; flex-direction:column;">
                    <img src="assets/images/p4-id-20.jpg" style="width:100%; height:100%; object-fit:cover; flex:1;">
                </figure>

                <figure class="exp-block" style="margin:0; padding:0; display:flex; flex-direction:column;">
                    <img src="assets/images/p4-id-21.jpg" style="width:100%; height:100%; object-fit:cover; flex:1;">
                </figure>

                <figure class="exp-block" style="margin:0; padding:0; display:flex; flex-direction:column;">
                    <img src="assets/images/p4-id-22.jpg" style="width:100%; height:100%; object-fit:cover; flex:1;">
                </figure>

                <figure class="exp-block" style="margin:0; padding:0; display:flex; flex-direction:column;">
                    <img src="assets/images/p4-id-23.jpg" style="width:100%; height:100%; object-fit:cover; flex:1;">
                </figure>

            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Process & Challenges</strong></h3>
                </div>

                <div class="exp-block">
                    <p>Building this experiment required designing three distinct visual systems: camera, drawing layer,
                        and ASCII transformation, while ensuring they remained perfectly aligned, consistent, and
                        responsive. The central challenge was synchronising three representations of the same identity
                        using different forms of data: pixels, drawn strokes, and ASCII characters.</p>
                    <p>The first technical hurdle was constructing fixed 1:1 boxes that always maintained a real camera
                        aspect ratio without distortion. This required manually calculating the aspect ratio,
                        recomputing the layout on resize, and ensuring the camera was mirrored correctly using
                        scale(-1,1). Any misalignment distorted the user’s reflection, making the left panel feel
                        uncanny.
                    </p>
                    <p>The second major challenge was unifying the drawing layer and the ASCII layer. Both had to be the
                        exact same resolution so that the ASCII output represented the drawing pixel-for-pixel. This
                        meant mapping mouse input from screen coordinates into drawing-layer coordinates precisely,
                        which revealed problems such as:<br>• incorrect mapping when resizing the window<br>• the drawn
                        strokes appearing offset<br>• pixel density mismatches causing incorrect ASCII
                        brightness<br>• ASCII text overflowing outside its box<br>These were solved by locking both
                        layers to a shared rendering size (640×480) and carefully mapping mouse input using map().</p>
                    <p>The ASCII conversion also gave me issues because it needed to update in real time, so that code
                        has to:<br>• compute brightness from sampled pixels<br>• map each value to a character from a
                        controlled ASCII ramp<br>• ensure each ASCII character sits inside its own grid
                        cell<br>• prevent jitter, stretching, or misalignment</p>
                    <p>Finally, balancing coverage vs. readability required tuning the number of columns and rows so the
                        ASCII fully filled the panel but remained legible.</p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/w15-hero.jpg" alt="">
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Moving Forward</strong></h3>
                </div>

                <div class="exp-block">
                    <p>For the next semester, I would like to expand my work beyond p5.js. Some considerables:
                        TouchDesigner, Arduino, Processing, Three.js, and ML5.js. During the holidays, I plan to
                        research more into the type of data that is being collected and what's not. With the
                        experimentation over the holidays, I will keep in mind and tie it close to my three pillars.
                        Ultimately, I will start planning for the exhibition design of this project.</p>
                </div>
            </section>

            <!-- BOTTOM-RIGHT FLOATING NAV BUTTONS -->
            <div class="week-nav-controls">
                <button class="week-nav-btn" id="prevWeek">←</button>
                <button class="week-nav-btn" id="topBtn">↑</button>
                <button class="week-nav-btn" id="nextWeek">→</button>
            </div>


        </main>

    </div>


    <!-- ACCORDION SCRIPT -->

    <script>
        document.addEventListener("DOMContentLoaded", () => {

            /* -----------------------------
               1) LEFT NAV ACCORDION TOGGLES
            ------------------------------ */
            document.querySelectorAll(".overview-group").forEach(group => {
                const toggleBtn = group.querySelector(".nav-toggle");
                const symbol = group.querySelector(".nav-toggle-symbol");

                if (!toggleBtn || !symbol) return;

                // default closed
                group.classList.remove("is-open");
                toggleBtn.setAttribute("aria-expanded", "false");
                symbol.textContent = "+";

                toggleBtn.addEventListener("click", () => {
                    const isOpen = group.classList.toggle("is-open");
                    toggleBtn.setAttribute("aria-expanded", isOpen ? "true" : "false");
                    symbol.textContent = isOpen ? "−" : "+";
                });
            });


            /* -----------------------------
               2) BOTTOM-RIGHT WEEK NAV
            ------------------------------ */
            const prev = document.getElementById("prevWeek");
            const next = document.getElementById("nextWeek");
            const topBtn = document.getElementById("topBtn");

            // Scroll to top
            if (topBtn) {
                topBtn.addEventListener("click", () => {
                    window.scrollTo({ top: 0, behavior: "smooth" });
                });
            }

            // Detect semester + week from URL
            // Works with GitHub Pages paths like:
            // /algorithmic-identities/semester-1/week-15.html
            const path = window.location.pathname;
            const match = path.match(/semester-(\d+)\/week-(\d+)\.html$/);

            // If this page is NOT a week page, just stop here.
            if (!match) return;

            const semester = parseInt(match[1], 10);
            const currentWeek = parseInt(match[2], 10);

            // Set last week per semester (edit SEM 2 when ready)
            const LAST_WEEK_BY_SEMESTER = {
                1: 15,
                2: 15
            };
            const lastWeek = LAST_WEEK_BY_SEMESTER[semester] ?? 15;

            // Prev button
            if (prev) {
                if (currentWeek <= 1) {
                    prev.style.display = "none";
                } else {
                    prev.addEventListener("click", () => {
                        window.location.href = `semester-${semester}/week-${currentWeek - 1}.html`;
                    });
                }
            }

            // Next button
            if (next) {
                if (currentWeek >= lastWeek) {
                    next.style.display = "none";
                } else {
                    next.addEventListener("click", () => {
                        window.location.href = `semester-${semester}/week-${currentWeek + 1}.html`;
                    });
                }
            }

        });
    </script>

</body>

</html>