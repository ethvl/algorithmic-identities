<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>A-I: S1-W9</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <base href="/algorithmic-identities/">

    <link rel="icon" href="favicon.png" />
    <link rel="stylesheet" href="/algorithmic-identities/assets/styles.css">
</head>

<body>

    <div class="page-shell">

        <!-- FIXED LEFT NAV BAR -->
        <aside class="left-rail">
            <div class="site-title-block">
                <div class="site-kicker"><a href="index.html">A-I: Algorithmic Identities</a></div>
                <p class="site-description">
                    A design-research project exploring how our digital identities are co-constructed by algorithms,
                    shaping who we become online.
                </p>
            </div>

            <!-- NAVIGATION -->
            <nav class="nav-groups">
                <div class="nav-group overview-group">
                    <button class="nav-toggle" aria-expanded="false">
                        <span>SEM 1 / OVERVIEW</span>
                        <span class="nav-toggle-symbol">+</span>
                    </button>

                    <ul class="overview-weeks">
                        <li><a href="semester-1/week-1.html"><strong>W1</strong> : Prologue</a></li>
                        <li><a href="semester-1/week-2.html"><strong>W2</strong> : Atelier Presentation</a></li>
                        <li><a href="semester-1/week-3.html"><strong>W3</strong> : Mindmap & E-1</a></li>
                        <li><a href="semester-1/week-4.html"><strong>W4</strong> : RPO Plan & P-1</a></li>
                        <li><a href="semester-1/week-5.html"><strong>W5</strong> : RPO Consult & RE-1</a></li>
                        <li><a href="semester-1/week-6.html"><strong>W6</strong> : RPO Peer Reviews</a></li>
                        <li><a href="semester-1/week-7.html"><strong>W7</strong> : Formative Assessment</a></li>
                        <li><a href="semester-1/week-8.html"><strong>W8</strong> : E-2</a></li>
                        <li><a href="semester-1/week-9.html" class="active"><strong>W9</strong> : ASM & AxiDraw</a></li>
                        <li><a href="semester-1/week-10.html"><strong>W10</strong> : Task-Based Making</a></li>
                        <li><a href="semester-1/week-11.html"><strong>W11</strong> : E-3 - 6</a></li>
                        <li><a href="semester-1/week-12.html"><strong>W12</strong> : P-2</a></li>
                        <li><a href="semester-1/week-13.html"><strong>W13</strong> : Cohort Presentation</a></li>
                        <li><a href="semester-1/week-14.html"><strong>W14</strong> : P-3</a></li>
                        <li><a href="semester-1/week-15.html"><strong>W15</strong> : E-7 & P-4</a></li>
                    </ul>
                </div>

                <div class="nav-group overview-group">
                    <button class="nav-toggle" aria-expanded="false">
                        <span>SEM 2 / OVERVIEW</span>
                        <span class="nav-toggle-symbol">+</span>
                    </button>

                    <ul class="overview-weeks">
                        <li><a href="semester-2/week-1.html"><strong>W1</strong> : SEM-1 Review</a></li>
                        <li><a href="semester-2/week-2.html"><strong>W2</strong> : E-8</a></li>
                        <li><a href="semester-2/week-3.html"><strong>W3</strong> : P-6 & GDI Interview</a></li>
                    </ul>
                </div>

                <div class="nav-group"><a class="nav-link" href="catalogue.html">Catalogue of Making</a></div>
                <div class="nav-group"><a class="nav-link" href="repository.html">Repository</a></div>
                <div class="nav-group"><a class="nav-link" href="about.html">About</a></div>
            </nav>

            <div class="left-rail-footer">
                © ETHEL LIM<br>
                CiD / 2025
            </div>
        </aside>


        <!-- RIGHT PANEL — TWO COLUMN CONTENT -->

        <main class="right-panel">

            <section class="catalogue-sidebar">
                <h1><strong>Week 9</strong> / ASM & AxiDraw</h1>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Dissertation Consult</strong></h3>
                </div>

                <div class="exp-block">
                    <p>This week’s consultation focused on refining the clarity and coherence of my dissertation
                        proposal. Andreas provided positive feedback on the overall writing style, structure, and
                        integration of research, while highlighting areas that require sharper definition, particularly
                        around objectives, terminology, and conceptual framing.</p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/dissertation-feedback.jpg" alt="" style="object-fit: contain;">
                <figcaption style="font-size: 12px; text-align: left;">
                    <strong>Dissertation Consult Feedback</strong><em> Andreas</em>
                </figcaption>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Feedback Breakdown</strong></h3>
                </div>

                <div class="exp-block">
                    <h3><strong>Research Question and Objectives</strong></h3>
                    <p>My research has three modes of inquiry and each serves a different function, but are connected by
                        the same overarching research question.</p>
                    <p><strong>⑴ Experiment</strong><br>These are early explorations such as quick studies or prototypes
                        that has helped me to investigate ideas conceptually and materially. It explores possibilities,
                        generate data, and understand the research question experientially.</p>
                    <p><strong>⑵ Data-Driven Visualisation</strong><br>This stage interprets or maps the insights from
                        the experiments into visual forms. It's where the translation of abstract algorithmic precesses
                        into perceivable, aesthetic outcomes begin. The aim is to reveal patterns, relationships, and
                        phenomenas behind algorithmic identity in a visible and comprehensive way.</p>
                    <p><strong>⑶ Interative Prototypes</strong><br>These are the final artefaces or installations that
                        embody the findings and allow audiences to engage directly. They extend the visualisations into
                        a participatory or immersive format which merges the research with digital exhibition design.
                        The purpose is to invite reflection, participation, and dialogue to test how the insights
                        function in real-time interaction.</p><br>
                    <h3><strong>Refining Research Question</strong></h3>
                    <p>• The research question should be overarching and broad enough to encompass all three parts.<br>•
                        The objectives are to answer the research question.<br>• The actions from the objectives are how
                        they are being fufilled, showing the methodology in motion.<br>• Each action should loop back to
                        answer or refine the research question.<br>• Current objectives can be less vague and more
                        explicit. It should be functional, actionable, and aligned to the methods.</p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/w9-hero.jpg" alt="">
                <figcaption style="font-size: 12px; text-align: left;">
                    <strong>Another World Is Possible</strong><em> ArtScience Museum</em>
                </figcaption>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>About Exhibition</strong></h3>
                </div>

                <div class="exp-block">
                    <h3>Another World Is Possible</h3>
                    <p>
                        This week, we went on a field trip to ArtScience Museum. The exhibition <strong>"Another World
                            Is
                            Possible"</strong> shares about how we imagine the future. At a time when dystopian visions
                        dominate
                        popular culture, bringing together over 100 exhibits shaped instead by resilience, creativity,
                        and hope.
                    </p>
                    <p> Unfolding across seven chapters, it explores the practice of world-building across cinema,
                        design, architecture, and literature. Drawing from Indigenous, Afrofuturist, and Asian
                        perspectives, the exhibition presents diverse ways of envisioning the future, forming an
                        aesthetic of tomorrow that is luminous, organic, and alive with possibility.
                    </p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/w9-1.jpeg" alt="">
                <figcaption style="font-size: 12px; text-align: left;">
                    <strong>14-channel-installation</strong><em> Syafiq Halid</em>
                </figcaption>
            </section>

            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Chapter 1: We are Authors of the End</strong></h3>
                </div>

                <div class="exp-block">
                    <p>
                        For more than a century, cinema and television have shaped how we imagine the future. Many
                        iconic films gave form to that anxiety of the future as something to fear, including Metropolis
                        (1927), to Blade Runner (1982), to The Matrix (1999). The future on screen was dominated by the
                        ominous rise of machine intelligence, the breakdown of societal order, and a planet scarred by
                        ecological collapse. Dystopia became the default, a shared visual language that was dark,
                        seductive, and hard to unlearn.
                    </p>
                    <p> The montage presents scenes of collapse, control, and catastrophe drawn from decades of cinema
                        and television. Presented in sequence, they reveal a visual vocabulary that has been absorbed
                        into public consciousness. The repetition of dystopian images has narrowed our capacity to see
                        otherwise.
                    </p><br>
                    <h3><strong>Thoughts</strong></h3>
                    <p>I was struck by how seamlessly sound, light, and spatial design came together to evoke this as a
                        living, responsive entity. The sense of a listening environment, one that perceives, processes,
                        and reacts... I felt that it deeply aligned with my research on algorithmic identities. Much
                        like the algorithms that constantly observe and adjust our digital experiences, Halid's work
                        embodied a system that learns from its audience in real time.</p>
                    <p>The lighting further amplified this dialogue, casting the space as both intimate and futuristic.
                        It was almost like a consciousness that remembers. I found this particularly resonant with my
                        exploration of how algorithmic systems construct identity through feedback loops. Here, the
                        audience became the data, and the environment became the algorithm, together forming a living
                        spectacle of perception, response, and self-awareness.</p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/w9-2.JPG" alt="">
                <figcaption style="font-size: 12px; text-align: left;">
                    <strong>Film of an Interdimensional Tribe</strong><em> Shiro Fujioka</em>
                </figcaption>
            </section>

            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Chapter 3: It Begins with Freedom</strong></h3>
                </div>

                <div class="exp-block">
                    <p>
                        This chapter introduces Afrofuturism, a cultural movement that places the experiences,
                        histories, and futures of the African diaspora at the centre of speculative thought.
                        Afrofuturism asks what the future might look like when shaped by the values of cultural memory,
                        spiritual depth, and self-determination.
                    </p>
                    <p> There is a radical cosmology that reverberates through the works in the gallery. This film by
                        Shiro Fujioka is about an interdimensional tribe that uses sound to move through time, space,
                        and Black futures.
                    </p><br>
                    <h3><strong>Thoughts</strong></h3>
                    <p>Beyond the content of the film, the exhibition design
                        itself heightened the sense of immersion: the projection dominated an entire wall, surrounded by
                        generous negative space that isolated the viewer's focus. The minimal setup: darkened lighting,
                        spatial stillness, and enveloping sound, invited contemplation which positioned the film almost
                        as a portal rather than a screen.</p>
                    <p>Fujioka's film drew me in with the visuals and soundscape. However, there was no mention anywhere
                        that AI was used as a creative tool. This absense raised a lingering question for me: <em>when
                            artists use AI as a creative tool, should its involvement be made transparent within the
                            exhibition context?</em> I felt conflicted.</p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/w9-3.JPG" alt="">
                <figcaption style="font-size: 12px; text-align: left;">
                    <strong>Cloud Scripts</strong><em> Ong Kian Peng</em>
                </figcaption>
            </section>

            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Chapter 4: Silk, Spice, a Punk Paradise</strong></h3>
                </div>

                <div class="exp-block">
                    <p>
                        This generative art installation, a conceptual machine, delves into the asemic essence of Daoist
                        'Cloud seals', positing them as a bridge for communication between humanity and the spiritual
                        realm. By compiling a collection of 'Cloud Seals' from Daoist scriptures and employing a
                        fine-tuned generative AI, the installation crafts unique talismans. These talismans,
                        intentionally devoid of concrete pictorial meaning, embody Ong's aspiration for a spiritual
                        dialogue, with his created data and software serving as a machine-expressed missive to the
                        spiritual world.
                    </p>
                    <p> Ong compels us to reconsider the conventional view of machines as solely utilitarian, fast, and
                        efficient. He probes the potential for machines to act as intermediaries between humanity and
                        the spiritual domain. This provocative question leads him to the rich traditions of Daoist
                        writing, wherein characters are imbued with profound spiritual power, functioning as channels
                        for divine communion. Within Daoist esoteric practices, written texts transcend their
                        informational role, becoming sacred directives capable of connecting the human and the spiritual
                        realms.
                    </p><br>
                    <h3><strong>Thoughts</strong></h3>
                    <p>This is my favourite piece of work from the entire exhibition. Ong's work was the most
                        outstanding, and it impressed me with its ability to turn code/data into something poetic and
                        ritualistic. The seals don't carry literal meaning but evoke spiritual, symbolic resonance. That
                        transformation from algorithmic logic into symbolic form is neat. The conceptual layering is
                        rich as he draws from Daoist traditions of writing as sacred/spiritual communication, and posits
                        that machines and code can act as mediators or translators of that. It also subtly critiques
                        modern machine logic (efficiency, speed, abstraction) by re-introducing a slower, mediative
                        machine practice oriented toward nature, spirit, ritual.</p>
                    <p>Given my focus on how algorithms, data systems and media design can help construct identity,
                        perception and experience, this piece from Ong offers multiple rich points of relevance:</p>
                    <p><strong>⑴ Visibility / Invisibility of the System</strong><br>The installation makes visible the
                        machinery, the plotter, the material, the custom software; but also evokes something invisible
                        (the spiritual realm, cloud seals, algorithmic logic). This duality is important for my work on
                        exhibition design because it makes me question: <em>how do we design experiences where the
                            algorithmic component is perceptible yet not overt, where the viewer senses there's a system
                            at
                            work, without being overwhelmed by the technical?</em></p>
                    <p><strong>⑵ Reflection on Agency and Authorship</strong><br>The talismans are generated by a
                        machine guided by data and code... so.. <em>Who is the author? What identity is being
                            produced?</em> This links
                        directly to my concern about algorithmic identities: <em>who or what constructs them, how
                            transparent is the process, what agency remains with the human, what does the machine
                            contribute?</em></p>
                </div>
            </section>

            <!-- ROW 1 — FULL WIDTH IMAGE (16:9 landscape) -->
            <section class="exp-row full">
                <img src="assets/images/barc-game.jpg" alt="">
                <figcaption style="font-size: 12px; text-align: left;">
                    <strong>BARC</strong><em> Interactive Media Lab</em>
                </figcaption>
            </section>

            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Chapter 5: From Console to Cosmos</strong></h3>
                </div>

                <div class="exp-block">
                    <p>
                        <strong>BARC</strong> is a multiplayer arcade shooter game where players must scan barcodes in
                        both the virtual and physical world to complete different objectives. Players take on the role
                        of a warehouse employee equipped with a magical barcode scanner. Game tasks are delivered to the
                        player via a receipt printer in the real world, and players must manage the onslaught of virtual
                        agents and torrent of physical receipts to complete their shift It invites collaboration and
                        playful resistance to standard game mechanics.
                    </p>
                    <p> It plays a part in inviting players to become co-creators of new worlds, exercising agency,
                        shaping outcomes, and taking responsibility. Each player becomes both inhabitant and guardian of
                        a possible future.
                    </p><br>
                    <h3><strong>Thoughts</strong></h3>
                    <p>This is an insightful case for the research's <strong>Digital Exhibition Design</strong> pillar.
                        It fits into the framework of translating invisible algorithmic systems into visible,
                        participatory, and sensory experiences. It creates immersive and interactive in-person
                        experiences using digital technologies to present content and tell a story.</p>
                    <p><strong>⑴ Marking AI Tangible through Embodied Interaction</strong><br>• Embodied metaphors
                        (gesture, sound, motion, or form) to help audiences feel the invisible relationship, instead of
                        just reading about it.<br>• Front-end visual and textual interface evokes a sense of response.
                    </p>
                    <p><strong>⑵ Relationship Between Human, Machine, and Environment</strong><br>The game positions the
                        robot, human, and AI as mutually responsive agents, not separate entities, but part of one
                        dynamic system. There is a system mapping: <strong>frontend ↔ backend ↔ user input</strong>.</p>
                </div>
            </section>

            <!-- ROW 4 — FULL WIDTH IMAGE -->
            <section class="exp-row full">
                <div style="position:relative; width:100%; padding-bottom:56.25%; overflow:hidden;">
                    <iframe src="https://player.vimeo.com/video/1130813039?autoplay=1&muted=1&loop=1&background=1"
                        frameborder="0" allow="autoplay; fullscreen; picture-in-picture"
                        style="position:absolute; top:0; left:0; width:100%; height:100%; border:0;">
                    </iframe>
                </div>
                <figcaption style="font-size: 12px; text-align: left;"><strong>Quick, Draw! Demo</strong><em>
                        Google</em></figcaption>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>ArtScience Museum Laboratory</strong></h3>
                </div>

                <div class="exp-block">
                    <p><strong>Quick, Draw! by Google</strong><br>is an online game where a neural network tries to
                        guess what the user is drawing, acting like an AI pictionary. Players are given a prompt to draw
                        an object, and as they draw, the AI attempts to identify it in real-time using its training on
                        millions of other users' doodles. This game was developed to be an accessible and fun way to
                        explore how machine learning works and to collect a massive dataset of drawings for future
                        research.</p>
                    <p>This large-scale collection contributed by participants worldwide contains drawings stored as
                        time series of pencil positions (strokes) rather than bitmap images. It has the X/Y coordinates
                        and timing information of each stroke that is stored. Each drawing is tagged with metadata such
                        as the drawing category, IP address, AI recognition. The files are in <strong>NDJSON
                            format.</strong></p><br>
                    <h3><strong>JSON vs NDJSON</strong></h3>
                    <p>I was quite curious about what <strong>NDJSON</strong> was since the format that I am familiar
                        with is <strong>JSON.</strong> After researching about the difference between both, I've learnt
                        that <strong>JSON</strong> is a single, self-contained unit (object or arrray). It requires
                        parsing of the entire file. There are API responses for single entities. However,
                        <strong>NDJSON</strong> contains multiple independent <strong>JSON</strong> objects, each on a
                        new line. It is parsed line by line and processes incrementally. <strong>NDJSON</strong> is
                        better suited for large datasets and streaming data.
                    </p><br>
                    <h3><strong>Thoughts & Relevance to Research</strong></h3>
                    <p>This activity is simple, yet it reveals an example of how user interaction feeds algorithmic
                        learning. The game invites players to sketch prompts in seconds while the neutral network
                        attempts to identify each drawing in real-time. What appears playful is actually a massive
                        data-collection mechanism. Each drawing becomes a part of the growing dataset which now contains
                        over 50 million sketches used to train machine-learning models to recognise shapes, gestures,
                        and patterns. This connects directly to my research on algorithmic identities: users unknowingly
                        contribute fragments of their behaviour, style, and cognition to a collective data body that
                        algorithms learn from and refine. The game visualises how everyday participation, something as
                        innocent as a doodle, can become a part of <strong>datafication in action.</strong> It
                        demonstrates both the creative and extractive dimensions of human-machine interaction.</p>
                </div>
            </section>

            <!-- 4 COLUMNS -->
            <section class="exp-row cols-4">
                <div class="exp-block"><img src="assets/images/w9-4.jpeg"></div>
                <div class="exp-block"><img src="assets/images/w9-5.jpg"></div>
                <div class="exp-block"><img src="assets/images/w9-6.jpg"></div>
                <div class="exp-block"><img src="assets/images/w9-7.jpeg"></div>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Atelier Workshop: AxiDraw</strong></h3>
                </div>

                <div class="exp-block">
                    <p>In this week's atelier workshop, we experimented with the AxiDraw plotter. It translates digital
                        designs into precise, physical drawings. What fascinated me was how this process bridged the gap
                        between screen-based code and tangible form, revealing the tactile potential of expression. The
                        AxiDraw made visible what is often hidden: the slow, delibrate movement of a machine intepreting
                        human input. This translation from the digital to physical not only reintroduces materiality
                        into computational work, but also raises questions: how does the algorithmic authorship shift
                        when the output gains physical presence? This experiment of making highlighted the poetic
                        tension between control and unpredictability, where both the human and the machine leave traces
                        in the final work.</p>
                </div>
            </section>

            <!-- ROW 4 — FULL WIDTH IMAGE -->
            <section class="exp-row full">
                <figure style="margin:0; padding:0; display:flex; flex-direction:column;">

                    <div style="position:relative; width:100%; padding-bottom:56.25%; overflow:hidden;">
                        <iframe src="https://player.vimeo.com/video/1130819321?autoplay=1&muted=1&loop=1&background=1"
                            frameborder="0" allow="autoplay; fullscreen; picture-in-picture"
                            style="position:absolute; top:0; left:0; width:100%; height:100%; border:0;">
                        </iframe>
                    </div>

                    <figcaption style="font-size:12px; margin-top:20px; text-align:left;">
                        <strong>AxiDraw Experimentation</strong> <em>Vimeo</em>
                    </figcaption>

                </figure>
            </section>

            <!-- ROW 2 — SPLIT ROW -->
            <section class="exp-row split">
                <div class="exp-block">
                    <h3><strong>Reflection</strong></h3>
                </div>

                <div class="exp-block">
                    <p>This week's experience made me think deeply about how the machine can act not just as a tool, but
                        as an expressive collaborator. Across the works encountered, <strong>Cloud Scripts, Quick,
                            Draw!, to AxiDraw workshop,</strong> the participant became both the creator and data
                        source. Their gestures are interpreted, translated, and archived by machines. There was an
                        interesting relationship that I took notice of: the human provides intent, but the machine gives
                        it form, sometimes even unpredictability.</p>
                    <p>This raised questions central to my research: <em>if machines can now "draw", "listen" and
                            "respond", where does human expression end, and algorithmic interpretation begin?</em> The
                        process revealed how every mark or input becomes data, and how expression today is also
                        increasingly co-authored by systems that learn from us. It reminded me that to <strong>"draw
                            with machines"</strong> is also to negotiate control, authorship, and identity within a
                        shared algorithmic space.</p>
                </div>
            </section>


            <!-- BOTTOM-RIGHT FLOATING NAV BUTTONS -->
            <div class="week-nav-controls">
                <button class="week-nav-btn" id="prevWeek">←</button>
                <button class="week-nav-btn" id="topBtn">↑</button>
                <button class="week-nav-btn" id="nextWeek">→</button>
            </div>

        </main>

    </div>


    <!-- ACCORDION SCRIPT -->

    <script>
        document.addEventListener("DOMContentLoaded", () => {

            /* -----------------------------
               1) LEFT NAV ACCORDION TOGGLES
            ------------------------------ */
            document.querySelectorAll(".overview-group").forEach(group => {
                const toggleBtn = group.querySelector(".nav-toggle");
                const symbol = group.querySelector(".nav-toggle-symbol");

                if (!toggleBtn || !symbol) return;

                // default closed
                group.classList.remove("is-open");
                toggleBtn.setAttribute("aria-expanded", "false");
                symbol.textContent = "+";

                toggleBtn.addEventListener("click", () => {
                    const isOpen = group.classList.toggle("is-open");
                    toggleBtn.setAttribute("aria-expanded", isOpen ? "true" : "false");
                    symbol.textContent = isOpen ? "−" : "+";
                });
            });


            /* -----------------------------
               2) BOTTOM-RIGHT WEEK NAV
            ------------------------------ */
            const prev = document.getElementById("prevWeek");
            const next = document.getElementById("nextWeek");
            const topBtn = document.getElementById("topBtn");

            // Scroll to top
            if (topBtn) {
                topBtn.addEventListener("click", () => {
                    window.scrollTo({ top: 0, behavior: "smooth" });
                });
            }

            // Detect semester + week from URL
            // Works with GitHub Pages paths like:
            // /algorithmic-identities/semester-1/week-15.html
            const path = window.location.pathname;
            const match = path.match(/semester-(\d+)\/week-(\d+)\.html$/);

            // If this page is NOT a week page, just stop here.
            if (!match) return;

            const semester = parseInt(match[1], 10);
            const currentWeek = parseInt(match[2], 10);

            // Set last week per semester (edit SEM 2 when ready)
            const LAST_WEEK_BY_SEMESTER = {
                1: 15,
                2: 15
            };
            const lastWeek = LAST_WEEK_BY_SEMESTER[semester] ?? 15;

            // Prev button
            if (prev) {
                if (currentWeek <= 1) {
                    prev.style.display = "none";
                } else {
                    prev.addEventListener("click", () => {
                        window.location.href = `semester-${semester}/week-${currentWeek - 1}.html`;
                    });
                }
            }

            // Next button
            if (next) {
                if (currentWeek >= lastWeek) {
                    next.style.display = "none";
                } else {
                    next.addEventListener("click", () => {
                        window.location.href = `semester-${semester}/week-${currentWeek + 1}.html`;
                    });
                }
            }

        });
    </script>

</body>

</html>